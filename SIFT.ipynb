{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd359e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIR = './data'\n",
    "N_CLUSTERS = 10000    # BoVW 词典大小\n",
    "MAX_KP = 100         # 每张图最大关键点数\n",
    "PATCH_SIZE = 16     # 描述子 patch 大小\n",
    "INTEREST_METHOD = 'DoG'  # 可选: 'DoG', 'Harris', 'LoG'\n",
    "EPOCHS = 50\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup MPS device ---\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Interest Point Detection ---\n",
    "def detect_interest_points(gray, method='DoG', threshold=5):\n",
    "    if method == 'DoG':\n",
    "        # Define multiple sigma values for Gaussian blur\n",
    "        num_octaves=3 # the level of the image pyramid\n",
    "        scales_per_octave=3 # the number of scales per octave\n",
    "        sigma0=1.6 # otiginal sigma value\n",
    "        \n",
    "        keypoints = []\n",
    "        k = 2 ** (1 / scales_per_octave)  # 每层之间的尺度倍增因子\n",
    "        \n",
    "        # form the 0th octave to num_octaves-1 octaves\n",
    "        for octave in range(num_octaves):\n",
    "            # 1) create the base image for the current octave\n",
    "            if octave == 0:\n",
    "                base = gray.copy()\n",
    "            else:\n",
    "                # 下采样前一个 octave 的 base\n",
    "                base = cv2.pyrDown(prev_base)\n",
    "            \n",
    "            # save the current base for the next octave\n",
    "            prev_base = base\n",
    "            # calculate the size of the base image\n",
    "            h, w = base.shape\n",
    "            \n",
    "            # 2) 构建本 octave 的 Gaussian 金字塔\n",
    "            #    需要做 (scales_per_octave + 3) 层，以便产生 scales_per_octave+2 个 DoG 层\n",
    "            sigmas = [sigma0 * (k ** (i + octave*scales_per_octave)) for i in range(scales_per_octave + 3)]\n",
    "            gaussians = [cv2.GaussianBlur(base, (0,0), sigmaX=s) for s in sigmas]\n",
    "            \n",
    "            # 3) 计算 DoG 图层\n",
    "            dogs = []\n",
    "            for i in range(len(gaussians)-1):\n",
    "                diff = gaussians[i+1].astype(np.float32) - gaussians[i].astype(np.float32)\n",
    "                dogs.append(diff)\n",
    "            \n",
    "            # 4) 在空间 + 尺度域寻找极值点\n",
    "            #    只从第 1 层到倒数第 2 层做比较，因为要用前后层做上下尺度比较\n",
    "            for i in range(1, len(dogs)-1):\n",
    "                # the three layers to compare\n",
    "                prev_d, curr_d, next_d = dogs[i-1], dogs[i], dogs[i+1]\n",
    "\n",
    "                # max_spat and min_spat are masks of the same size as curr_d\n",
    "                # 空间极值：用形态学膨胀/腐蚀检测局部极大/极小值\n",
    "                # 对 curr_d 做形态学膨胀（dilation），相当于每个像素点被它 3×3 邻域内的最大值取代。\n",
    "                #curr_d 在每个像素的 3×3 邻域内取最大值，输出也是一个 (H, W) 的数组——max_spat[y, x] 就是 curr_d 在 (y, x) 周围那 9 个点里的最大值。\n",
    "                max_spat = cv2.dilate(curr_d, np.ones((3,3),np.uint8))\n",
    "                # 做腐蚀（erosion），相当于每个像素点被邻域内的最小值取代。\n",
    "                min_spat = cv2.erode( curr_d, np.ones((3,3),np.uint8))\n",
    "                \n",
    "                # 跨尺度极值：要比前一 DoG 和后一 DoG 都大（或都小）\n",
    "                mask_max = (curr_d == max_spat) & (curr_d > prev_d) & (curr_d > next_d) & (np.abs(curr_d) > threshold)\n",
    "                mask_min = (curr_d == min_spat) & (curr_d < prev_d) & (curr_d < next_d) & (np.abs(curr_d) > threshold)\n",
    "                \n",
    "                # Find all coordinates of the points that satisfy the conditions\n",
    "                coords = np.vstack((np.argwhere(mask_max), np.argwhere(mask_min)))\n",
    "\n",
    "                # 5) 将坐标映射回原图尺度并创建 KeyPoint\n",
    "                for y, x in coords:\n",
    "                    # 因为后面可能 downsample 了，需要乘回 2**octave\n",
    "                    scale = (2 ** octave)\n",
    "\n",
    "                    kp = cv2.KeyPoint(float(x*scale), float(y*scale), size=PATCH_SIZE * scale)\n",
    "                    keypoints.append(kp)\n",
    "                    \n",
    "        # 最后按响应或数量截断\n",
    "        keypoints = sorted(keypoints, key=lambda kp: kp.response if hasattr(kp, 'response') else 1.0,\n",
    "                        reverse=True)\n",
    "        return keypoints[:MAX_KP]\n",
    "    elif method == 'Harris':\n",
    "        harris = cv2.cornerHarris(gray.astype(np.float32), 2, 3, 0.04)\n",
    "        coords = np.argwhere(harris > threshold * harris.max())\n",
    "    elif method == 'LoG':\n",
    "        log = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        coords = np.argwhere(np.abs(log) > threshold)\n",
    "    else:\n",
    "        sift = cv2.SIFT_create()\n",
    "        kps = open_kps = sift.detect(gray, None)\n",
    "        # raise ValueError('Unsupported method')\n",
    "    # Create keypoints and limit count\n",
    "    return kps[:MAX_KP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Compute Custom SIFT-like Descriptor ---\n",
    "def compute_custom_sift_descriptor(gray, keypoints, patch_size=PATCH_SIZE):\n",
    "    # Compute gradients once\n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag = cv2.magnitude(grad_x, grad_y)\n",
    "    ori = cv2.phase(grad_x, grad_y, angleInDegrees=True)\n",
    "\n",
    "    descriptors = []\n",
    "    half = patch_size // 2\n",
    "    h, w = gray.shape\n",
    "\n",
    "    for kp in keypoints:\n",
    "        x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "        # boundary check\n",
    "        if x-half < 0 or y-half < 0 or x+half >= w or y+half >= h:\n",
    "            continue\n",
    "        # extract full patch\n",
    "        mag_full = mag[y-half:y+half, x-half:x+half]\n",
    "        ori_full = ori[y-half:y+half, x-half:x+half]\n",
    "        # 1) Orientation assignment: build 36-bin histogram over full patch\n",
    "        hist8, bin_edges = np.histogram(\n",
    "            ori_full.ravel(), bins=8, range=(0,360), weights=mag_full.ravel()\n",
    "        )\n",
    "        # main orientation is center of max bin\n",
    "        max_idx = np.argmax(hist8)\n",
    "        main_ori = (bin_edges[max_idx] + bin_edges[max_idx+1]) / 2.0\n",
    "        # normalize full patch orientations relative to main orientation\n",
    "        ori_full = (ori_full - main_ori + 360) % 360\n",
    "\n",
    "        # slice into subregions and build descriptor\n",
    "        desc = []\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                sub_mag = mag_full[i*4:(i+1)*4, j*4:(j+1)*4].ravel()\n",
    "                sub_ori = ori_full[i*4:(i+1)*4, j*4:(j+1)*4].ravel()\n",
    "                # 2) histogram on aligned orientations\n",
    "                hsub, _ = np.histogram(sub_ori, bins=8, range=(0,360), weights=sub_mag)\n",
    "                desc.extend(hsub)\n",
    "        desc = np.array(desc, dtype=np.float32)\n",
    "        desc /= (np.linalg.norm(desc) + 1e-7)\n",
    "        descriptors.append(desc)\n",
    "\n",
    "    return np.array(descriptors) if descriptors else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Load CIFAR-10 ---\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "transform = transforms.Compose([\n",
    "    # 先把 32×32 放大到 128×128\n",
    "    transforms.Resize((128, 128), interpolation=InterpolationMode.BICUBIC),\n",
    "\n",
    "    # # 再做常见的数据增强（可按需打开/调整顺序）\n",
    "    # transforms.RandomCrop(120, padding=4),           # 随机裁剪到 120×120 并 pad\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),          # 随机水平翻转\n",
    "    # transforms.ColorJitter(brightness=0.2,\n",
    "    #                        contrast=0.2,\n",
    "    #                        saturation=0.2,\n",
    "    #                        hue=0.1),                  # 随机色相／亮度／对比度扰动\n",
    "\n",
    "    # 转成 Tensor 并归一化到 [0,1]\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # 再做标准化（CIFAR-10 通常用以下均值/方差）\n",
    "    # transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "    #                      std =[0.2470, 0.2435, 0.2616]),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10(DATA_DIR, train=True, download=True, transform=transform)\n",
    "testset  = CIFAR10(DATA_DIR, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 准备逆标准化，以便可视化\n",
    "# mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3,1,1)\n",
    "# std  = torch.tensor([0.2470, 0.2435, 0.2616]).view(3,1,1)\n",
    "# inv_norm = transforms.Normalize((-mean/std).squeeze(), (1/std).squeeze())\n",
    "\n",
    "indices = random.sample(range(len(trainset)), 10)\n",
    "imgs = []\n",
    "for idx in indices:\n",
    "    img, _ = trainset[idx]      # 返回 (C,H,W) tensor\n",
    "    # img = inv_norm(img)        # 逆归一化到 [0,1]\n",
    "    # img = torch.clamp(img, 0, 1)\n",
    "    imgs.append(img)\n",
    "\n",
    "grid = make_grid(imgs, nrow=5, padding=2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(grid.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Extract descriptors from training set ---\n",
    "all_desc = []\n",
    "img_desc_idx = []\n",
    "train_labels = []\n",
    "print('Extracting training descriptors...')\n",
    "for img, label in tqdm(trainset, desc='Train images'):\n",
    "    img_np = (img.numpy().transpose(1,2,0) * 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    kps = detect_interest_points(gray, method=INTEREST_METHOD)\n",
    "    des = compute_custom_sift_descriptor(gray, kps)\n",
    "    if des is not None:\n",
    "        all_desc.extend(des)\n",
    "    img_desc_idx.append(len(all_desc))\n",
    "    train_labels.append(label)\n",
    "all_desc = np.vstack(all_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Build visual vocabulary ---\n",
    "kmeans = MiniBatchKMeans(n_clusters=N_CLUSTERS, batch_size=1000, verbose=1)\n",
    "kmeans.fit(all_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Build BoVW features for train ---\n",
    "def build_bovw(descriptors):\n",
    "    words = kmeans.predict(descriptors)\n",
    "    hist, _ = np.histogram(words, bins=np.arange(N_CLUSTERS+1))\n",
    "    return hist.astype(float) / (hist.sum() + 1e-7)\n",
    "\n",
    "train_feats = []\n",
    "start = 0\n",
    "# for idx in img_desc_idx:\n",
    "for idx in tqdm(img_desc_idx, desc='Building BoVW features'):\n",
    "    end = idx\n",
    "    if end - start > 0:\n",
    "        train_feats.append(build_bovw(all_desc[start:end]))\n",
    "    else:\n",
    "        train_feats.append(np.zeros(N_CLUSTERS, dtype=float))\n",
    "    start = end\n",
    "train_feats = np.array(train_feats)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Extract BoVW features for test set ---\n",
    "test_feats = []\n",
    "test_labels = []\n",
    "print('Extracting test BoVW features...')\n",
    "for img, label in tqdm(testset, desc='Test images'):\n",
    "    img_np = (img.numpy().transpose(1,2,0) * 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    kps = detect_interest_points(gray, method=INTEREST_METHOD)\n",
    "    des = compute_custom_sift_descriptor(gray, kps)\n",
    "    if des is not None:\n",
    "        hist = build_bovw(des)\n",
    "    else:\n",
    "        hist = np.zeros(N_CLUSTERS, dtype=float)\n",
    "    test_feats.append(hist)\n",
    "    test_labels.append(label)\n",
    "\n",
    "test_feats = np.array(test_feats)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2a9e5",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a28ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 8. Train Softmax Regression (Logistic Regression) on MPS ---\n",
    "# # Prepare PyTorch tensors\n",
    "# X_train = torch.from_numpy(train_feats).float().to(device)\n",
    "# y_train = torch.from_numpy(train_labels).long().to(device)\n",
    "# X_test  = torch.from_numpy(test_feats).float().to(device)\n",
    "# y_test  = torch.from_numpy(test_labels).long().to(device)\n",
    "\n",
    "# # Define simple linear model\n",
    "# model = nn.Linear(N_CLUSTERS, 10).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "# print('Training Softmax Regression...')\n",
    "# for ep in range(1, EPOCHS+1):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_train)\n",
    "#     loss = criterion(outputs, y_train)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if ep % 5 == 0:\n",
    "#         print(f'Epoch {ep}/{EPOCHS}, loss={loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c547ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 9. Evaluate on test set ---\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     preds = model(X_test).argmax(dim=1)\n",
    "#     acc = (preds == y_test).float().mean().item()\n",
    "# print(f'Test Accuracy: {acc:.4f}')\n",
    "# # Convert MPS tensor to CPU numpy for classification_report\n",
    "# preds_np = preds.cpu().numpy()\n",
    "# print(classification_report(test_labels, preds_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b37b61",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fe432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定义一个 Pipeline，把 StandardScaler 和 LinearSVC 串起来\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc',    LinearSVC(dual=False, max_iter=500, random_state=42, verbose=2))\n",
    "])\n",
    "\n",
    "# 2. 指定要搜索的超参数网格\n",
    "param_grid = {\n",
    "    'svc__C':    [1],\n",
    "    'svc__tol':  [1e-4]\n",
    "}\n",
    "\n",
    "# 3. 构造 GridSearchCV：5 折交叉验证，使用所有 CPU 核心\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1, # 使用所有 CPU 核心\n",
    "    verbose=2, # 输出详细信息\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# 4. 在训练集上搜索最佳超参\n",
    "grid.fit(train_feats, train_labels)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV accuracy:\", grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cdb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 用最佳模型在测试集上评估\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(test_feats, test_labels)\n",
    "print(f\"Test accuracy with best SVM: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5184bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Randomly visualize classification results on test images ---\n",
    "import matplotlib.pyplot as plt\n",
    "# CIFAR-10 类别名称\n",
    "class_names = testset.classes\n",
    "# 随机选取几张图\n",
    "for idx in random.sample(range(len(testset)), 10):\n",
    "    img_t, label = testset[idx]\n",
    "    # Tensor [C,H,W] 转为 HxWxC uint8 图像\n",
    "    img_np = (img_t.numpy().transpose(1,2,0) * 255).astype(np.uint8)\n",
    "    # 构建 BoVW 特征\n",
    "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    kps = detect_interest_points(gray, method=INTEREST_METHOD)\n",
    "    des = compute_custom_sift_descriptor(gray, kps)\n",
    "    if des is None:\n",
    "        hist = np.zeros(N_CLUSTERS, dtype=float)\n",
    "    else:\n",
    "        hist = build_bovw(des)\n",
    "    # 标准化 & 预测\n",
    "    # X = scaler.transform(hist.reshape(1, -1)) if 'scaler' in globals() else hist.reshape(1, -1)\n",
    "    pred = best_model.predict(hist.reshape(1, -1))[0]\n",
    "    # 可视化\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(f\"GT: {class_names[label]}, Pred: {class_names[pred]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义 SVM 管道并开启 verbose 打印收敛信息，关闭 shrinking 提速\n",
    "# svm_fast = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     LinearSVC(\n",
    "#         penalty='l2',\n",
    "#         loss='squared_hinge',  # 改成 squared_hinge\n",
    "#         dual=False,            # n_samples > n_features 时推荐 False\n",
    "#         max_iter=5000,\n",
    "#         tol=1e-4,\n",
    "#         verbose=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 在 train_feats / train_labels 上训练\n",
    "# svm_fast.fit(train_feats, train_labels)\n",
    "# print(\"SVM training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# # 1. 预测\n",
    "# svm_preds = svm_fast.predict(test_feats)\n",
    "\n",
    "# # 2. 整体准确率\n",
    "# acc = accuracy_score(test_labels, svm_preds)\n",
    "# print(f\"SVM Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# # 3. 详细报告\n",
    "# print(classification_report(test_labels, svm_preds))\n",
    "\n",
    "# # 4. （可选）混淆矩阵\n",
    "# cm = confusion_matrix(test_labels, svm_preds)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
