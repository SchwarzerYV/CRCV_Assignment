{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torch_optimizer as optim  # 提供 Ranger 优化器\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选模型：SimpleCNN 或 ResNet50\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "def get_model(name='resnet50', num_classes=10):\n",
    "    if name.lower() == 'resnet50':\n",
    "        model = torchvision.models.resnet50(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        model = SimpleCNN(num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42394a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    correct, total_loss = 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 超参数\n",
    "    batch_size = 128\n",
    "    lr = 1e-3\n",
    "    num_epochs = 20\n",
    "    model_name = 'resnet50'  # 可选：'simplecnn' 或 'resnet50'\n",
    "\n",
    "    # --- Setup MPS device ---\n",
    "    device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "\n",
    "    # 数据增强与标准化\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "\n",
    "        transforms.RandomCrop(120, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2430, 0.2610))\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2430, 0.2610))\n",
    "    ])\n",
    "\n",
    "    # 加载训练集并拆分为 train/val\n",
    "    n_val = 5000\n",
    "    full_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "    n_train = len(full_train) - n_val\n",
    "    train_indices, val_indices = random_split(list(range(len(full_train))), [n_train, n_val])\n",
    "\n",
    "    # 分别创建 train 和 val 子集，各自使用不同 transform\n",
    "    train_set = Subset(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train),\n",
    "        train_indices.indices if hasattr(train_indices, 'indices') else train_indices\n",
    "    )\n",
    "    val_set = Subset(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_test),\n",
    "        val_indices.indices if hasattr(val_indices, 'indices') else val_indices\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader   = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 模型、损失、优化器\n",
    "    model = get_model(model_name).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Ranger(model.parameters(), lr=lr)\n",
    "\n",
    "    # get the information of the optimizer\n",
    "    print(optimizer)\n",
    "\n",
    "    # 训练与验证\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_epoch(model, device, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc = evaluate(model, device, val_loader, criterion)\n",
    "        print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc * 100:.2f}%\")\n",
    "        # 保存最优模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # 测试集评估\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    test_loss, test_acc = evaluate(model, device, test_loader, criterion)\n",
    "    print(f\"\\nFinal Test Loss: {test_loss:.4f} | Final Test Acc: {test_acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
