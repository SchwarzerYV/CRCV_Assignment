{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torch_optimizer as optim  # 提供 Ranger 优化器\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1fb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "num_epochs = 20\n",
    "model_name = 'resnet50'  # 可选：'simplecnn' 或 'resnet50'\n",
    "\n",
    "# --- Setup MPS device ---\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6fd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选模型：SimpleCNN 或 ResNet50\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "def get_model(name='resnet50', num_classes=10):\n",
    "    if name.lower() == 'resnet50':\n",
    "        model = torchvision.models.resnet50(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        model = SimpleCNN(num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42394a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    correct, total_loss = 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a0ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_index(full_train, train_ratio=0.8):\n",
    "    train_indices, val_indices = random_split(\n",
    "        list(range(len(full_train))),\n",
    "        [int(len(full_train) * train_ratio), len(full_train) - int(len(full_train) * train_ratio)]\n",
    "    )\n",
    "    return train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a4969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_augmentation(train_indices, val_indices):\n",
    "    # 数据增强与标准化\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "\n",
    "        transforms.RandomCrop(120, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2430, 0.2610))\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2430, 0.2610))\n",
    "    ])\n",
    "\n",
    "    train_set = Subset(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train),\n",
    "        train_indices.indices if hasattr(train_indices, 'indices') else train_indices\n",
    "    )\n",
    "    val_set = Subset(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_test),\n",
    "        val_indices.indices if hasattr(val_indices, 'indices') else val_indices\n",
    "    )\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ef019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集并拆分为 train/val\n",
    "full_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "train_indices, val_indices = split_train_val_index(full_train, train_ratio=0.8)\n",
    "\n",
    "# get train/val/test sets after data pre-processing and augmentation\n",
    "train_set, val_set, test_set = get_data_augmentation(train_indices, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger (\n",
      "Parameter Group 0\n",
      "    N_sma_threshhold: 5\n",
      "    alpha: 0.5\n",
      "    betas: (0.95, 0.999)\n",
      "    eps: 1e-05\n",
      "    k: 6\n",
      "    lr: 0.001\n",
      "    step_counter: 0\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mytorch/lib/python3.10/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value = 1) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Train Loss: 1.9154 | Val Loss: 1.7450 | Val Acc: 37.40%\n",
      "Epoch 01 | Train Loss: 1.4780 | Val Loss: 1.3336 | Val Acc: 51.47%\n",
      "Epoch 02 | Train Loss: 1.2491 | Val Loss: 1.2772 | Val Acc: 54.82%\n",
      "Epoch 03 | Train Loss: 1.0720 | Val Loss: 1.1537 | Val Acc: 59.79%\n",
      "Epoch 04 | Train Loss: 0.9241 | Val Loss: 0.8925 | Val Acc: 68.89%\n",
      "Epoch 05 | Train Loss: 0.8250 | Val Loss: 0.8123 | Val Acc: 71.11%\n",
      "Epoch 06 | Train Loss: 0.7251 | Val Loss: 0.6800 | Val Acc: 75.66%\n",
      "Epoch 07 | Train Loss: 0.6416 | Val Loss: 0.6667 | Val Acc: 77.08%\n",
      "Epoch 08 | Train Loss: 0.5728 | Val Loss: 0.6540 | Val Acc: 77.21%\n",
      "Epoch 09 | Train Loss: 0.5313 | Val Loss: 0.7083 | Val Acc: 75.52%\n",
      "Epoch 10 | Train Loss: 0.4791 | Val Loss: 0.8700 | Val Acc: 71.42%\n",
      "Epoch 11 | Train Loss: 0.4458 | Val Loss: 0.5106 | Val Acc: 82.61%\n",
      "Epoch 12 | Train Loss: 0.4163 | Val Loss: 0.5449 | Val Acc: 81.77%\n",
      "Epoch 13 | Train Loss: 0.3813 | Val Loss: 0.5040 | Val Acc: 82.97%\n",
      "Epoch 14 | Train Loss: 0.3624 | Val Loss: 0.5453 | Val Acc: 81.72%\n",
      "Epoch 15 | Train Loss: 0.3355 | Val Loss: 0.6306 | Val Acc: 79.89%\n",
      "Epoch 16 | Train Loss: 0.3130 | Val Loss: 0.6799 | Val Acc: 78.82%\n",
      "Epoch 17 | Train Loss: 0.3053 | Val Loss: 0.4742 | Val Acc: 84.58%\n",
      "Epoch 18 | Train Loss: 0.2800 | Val Loss: 0.4737 | Val Acc: 84.56%\n",
      "Epoch 19 | Train Loss: 0.2618 | Val Loss: 0.4623 | Val Acc: 85.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/5zx_gdxj5rvb7c3v91ml3v780000gn/T/ipykernel_98966/895155379.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.4944 | Final Test Acc: 84.23%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 模型、损失、优化器\n",
    "# model = get_model(model_name).to(device)\n",
    "\n",
    "# Use ResNet50 as the model\n",
    "num_classes = 10\n",
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# model = SimpleCNN(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Ranger(model.parameters(), lr=lr)\n",
    "\n",
    "# get the information of the optimizer\n",
    "print(optimizer)\n",
    "\n",
    "# 训练与验证\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, device, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, device, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc * 100:.2f}%\")\n",
    "    # 保存最优模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), './model/best_model_cnn_cifar.pth')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c410a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/5zx_gdxj5rvb7c3v91ml3v780000gn/T/ipykernel_98966/1345411143.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./model/best_model_cnn_cifar.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.4944 | Final Test Acc: 84.23%\n"
     ]
    }
   ],
   "source": [
    "# 测试集评估\n",
    "model.load_state_dict(torch.load('./model/best_model_cnn_cifar.pth'))\n",
    "test_loss, test_acc = evaluate(model, device, test_loader, criterion)\n",
    "print(f\"\\nFinal Test Loss: {test_loss:.4f} | Final Test Acc: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
